{
  "source": "true",
  "kind": "iteration",
  "timestamp": "2025-12-06T23:21:31.638353+00:00",
  "training_iteration": 28,
  "timesteps_total": 28672,
  "time_this_iter_s": 4.80616307258606,
  "time_total_s": 49.273717641830444,
  "episodes_total": null,
  "episodes_this_iter": null,
  "episode_reward_mean": null,
  "episode_reward_min": null,
  "episode_reward_max": null,
  "episode_len_mean": null,
  "num_env_steps_sampled": 28672,
  "num_env_steps_trained": 28672,
  "num_agent_steps_sampled": 57344,
  "num_agent_steps_trained": 57344,
  "env_steps_this_iter": 1024,
  "env_throughput": 213.2592395082855,
  "num_workers": 1,
  "custom_metrics": {},
  "policies": {
    "left_policy": {
      "reward_mean": -12.620764705882358,
      "reward_min": -23.150000000000006,
      "reward_max": 28.031999999999986,
      "episode_len_mean": null,
      "completed_episodes": null,
      "learner": {
        "num_agent_steps_trained": 128.0,
        "num_grad_updates_lifetime": 2280.5,
        "diff_num_grad_updates_vs_sampler_policy": 119.5,
        "allreduce_latency": 0.0,
        "grad_gnorm": 1.3656361823280652,
        "cur_kl_coeff": 0.10000000000000002,
        "cur_lr": 0.0003,
        "total_loss": 1.69799252251784,
        "policy_loss": -0.014719318827458968,
        "vf_loss": 3.4375390340884526,
        "vf_explained_var": 0.3719957947731018,
        "kl": 0.010047049733426575,
        "entropy": 0.7062384376923243,
        "entropy_coeff": 0.01
      }
    },
    "right_policy": {
      "reward_mean": 23.86745761647542,
      "reward_min": -9.256706998901372,
      "reward_max": 37.65859592356364,
      "episode_len_mean": null,
      "completed_episodes": null,
      "learner": {
        "num_agent_steps_trained": 128.0,
        "num_grad_updates_lifetime": 2280.5,
        "diff_num_grad_updates_vs_sampler_policy": 119.5,
        "allreduce_latency": 0.0,
        "grad_gnorm": 0.9452345038453738,
        "cur_kl_coeff": 0.14999999999999997,
        "cur_lr": 0.0003,
        "total_loss": 0.9101150774707397,
        "policy_loss": -0.013214122810556244,
        "vf_loss": 1.8591130991776785,
        "vf_explained_var": 0.1579514980316162,
        "kl": 0.012780323979195865,
        "entropy": 0.8144402345021565,
        "entropy_coeff": 0.01
      }
    }
  }
}